{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "\n",
    "sales=pd.read_csv(\"Dataset_3_sales.csv\", sep=\"|\",header=None)\n",
    "sales.columns = sales.iloc[0, :].tolist()\n",
    "sales = sales.drop(0, axis = 0).reset_index(drop = True)\n",
    "\n",
    "ID = sales.loc[:,'index']\n",
    "sales = sales.drop('index',axis = 1)\n",
    "sales = sales.rename(columns={sales.columns[0]: \"id\"})\n",
    "sales = sales.drop('id',axis =  1) \n",
    "sales = sales.drop(sales.columns[[0,1,2,3,4,5,6,7]],axis =  1) \n",
    "\n",
    "\n",
    "#print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Item_Identifier'] = sales['Item_Identifier'].astype(str)\n",
    "sales.loc[sales['Item_Identifier']=='-400','Item_Identifier']=np.nan\n",
    "sales.loc[sales['Item_Identifier']=='Allez au boulot ! :)','Item_Identifier']=np.nan\n",
    "sales.loc[sales['Item_Identifier']=='nan','Item_Identifier']=np.nan\n",
    "ID_Item = sales.loc[:,'Item_Identifier']\n",
    "sales=sales.drop('Item_Identifier', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-50fdd0918773>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales['Item_Weight'][y] = sales['Item_Weight'].mean() #remplace la valeur de product_cost par la moyenne\n"
     ]
    }
   ],
   "source": [
    "sales['Item_Weight'] = pd.to_numeric(sales['Item_Weight'], errors='coerce')\n",
    "for x, y in zip(sales.Item_Weight, sales.index): \n",
    "        rep = math.isnan(sales.Item_Weight[y]) #rep récupère l'emplacement des NaN dans product_cost\n",
    "        if rep == True : #si rep est un NaN \n",
    "            sales['Item_Weight'][y] = sales['Item_Weight'].mean() #remplace la valeur de product_cost par la moyenne\n",
    "#print(sales.Item_Weight)\n",
    "#sales.Item_Weight.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Item_Fat_Content'] = sales['Item_Fat_Content'].astype(str)\n",
    "sales['Item_Fat_Content'] = sales['Item_Fat_Content'].replace(['low fat', 'LF'], 'Low Fat')\n",
    "sales['Item_Fat_Content'] = sales['Item_Fat_Content'].replace(['reg'], 'Regular')\n",
    "sales['Item_Fat_Content'] = sales['Item_Fat_Content'].replace(['nan'], 'None')\n",
    "\n",
    "#print(sales.Item_Fat_Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Item_Visibility'] = sales['Item_Visibility'].astype(float)\n",
    "#print(sales.Item_Visibility)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Item_Type'] = sales['Item_Type'].astype(str)\n",
    "#print(sales.Item_Type)\n",
    "#sales.groupby('Item_Type').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Item_MRP'] = sales['Item_MRP'].astype(float)\n",
    "#print(sales.Item_MRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sales['Outlet_Identifier'] = sales['Outlet_Identifier'].astype(str)\n",
    "sales.loc[sales['Outlet_Identifier']=='nan','Outlet_Identifier']=np.nan\n",
    "ID_Outlet= sales.loc[:,'Outlet_Identifier']\n",
    "sales=sales.drop('Outlet_Identifier', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Outlet_Establishment_Year'] = sales['Outlet_Establishment_Year'].astype(float)\n",
    "#print(sales.Outlet_Establishment_Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Outlet_Size'] = sales['Outlet_Size'].astype(str)\n",
    "sales.loc[sales['Outlet_Size']=='nan','Outlet_Size']=\"0\"\n",
    "#sales.groupby('Outlet_Size').sum()\n",
    "#print(sales.Outlet_Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Outlet_Location_Type'] = sales['Outlet_Location_Type'].astype(str)\n",
    "sales.loc[sales['Outlet_Location_Type']=='nan','Outlet_Location_Type']=np.nan\n",
    "#sales.groupby('Outlet_Location_Type').sum()\n",
    "#print(sales.Outlet_Location_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Outlet_Location_Type'] = sales['Outlet_Location_Type'].astype(str)\n",
    "sales.loc[sales['Outlet_Location_Type']=='nan','Outlet_Location_Type']=np.nan\n",
    "#sales.groupby('Outlet_Type').sum()\n",
    "#print(sales.Outlet_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Item_Outlet_Sales'] = sales['Item_Outlet_Sales'].astype(float)\n",
    "#print(sales.Item_Outlet_Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_OHE=pd.DataFrame(OneHotEncoder().fit_transform(sales[[\"Item_Fat_Content\"]]).toarray())\n",
    "sales=sales.join(sales_OHE)\n",
    "sales=sales.drop('Item_Fat_Content', axis=1)\n",
    "sales=sales.rename(columns={0: \"Fat_Content_low_Fat\", 1:\"Fat_Content_None\",2:\"Fat_Content_Regular\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_OHE2=pd.DataFrame(OneHotEncoder().fit_transform(sales[[\"Item_Type\"]]).toarray())\n",
    "sales=sales.join(sales_OHE2)\n",
    "sales=sales.drop('Item_Type', axis=1)\n",
    "sales=sales.rename(columns={0:\"Type_Baking_Goods\", 1:\"Type_Breads\",2:\"Type_Breakfast\",3:\"Type_Canned\",4:\"Type_Dairy\",5:\"Type_Frozen_Foods\",6:\"Type_Fruits_and_Vegetables\",7:\"Type_Hard_Drinks\",8:\"Type_Health_and_Hygiene\",9:\"Type_Household\",10:\"Type_Meat\",11:\"Type_Other\",12:\"Type_Seafood\",13:\"Type_Snack_Food\",14:\"Type_Soft_Drink\",15:\"Type_Starchy_Foods\",})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_OHE3=pd.DataFrame(OneHotEncoder().fit_transform(sales[[\"Outlet_Size\"]]).toarray())\n",
    "sales=sales.join(sales_OHE3)\n",
    "sales=sales.drop('Outlet_Size', axis=1)\n",
    "sales=sales.rename(columns={0: \"Size_NO_Size\", 1:\"Size_High\",2:\"Size_Medium\",3:\"Size_Small\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_OHE4=pd.DataFrame(OneHotEncoder().fit_transform(sales[[\"Outlet_Location_Type\"]]).toarray())\n",
    "sales=sales.join(sales_OHE4)\n",
    "sales=sales.drop('Outlet_Location_Type', axis=1)\n",
    "sales=sales.rename(columns={0: \"Location_Type_Tier_1\", 1:\"Location_Type_Tier_2\",2:\"Location_Type_Tier_3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_OHE5=pd.DataFrame(OneHotEncoder().fit_transform(sales[[\"Outlet_Type\"]]).toarray())\n",
    "sales=sales.join(sales_OHE5)\n",
    "sales=sales.drop('Outlet_Type', axis=1)\n",
    "sales=sales.rename(columns={0: \"Type_Grocery_Store\", 1:\"Type_Supermarket_Type1\",2:\"Type_Supermarket_Type2\",3:\"Type_Supermarket_Type3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Item_Outlet_Sales'] = pd.to_numeric(sales['Item_Outlet_Sales'], errors='coerce')\n",
    "for x, y in zip(sales.Item_Outlet_Sales, sales.index): \n",
    "        rep1 = math.isnan(sales.Item_Outlet_Sales[y]) \n",
    "        if rep1 == True : \n",
    "            sales['Item_Outlet_Sales'][y] = sales['Item_Outlet_Sales'].mean()\n",
    "#print(sales.Item_Outlet_Sales)\n",
    "#sales.Item_Outlet_Sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest=RandomForestRegressor(n_estimators=100,min_samples_leaf=1) \n",
    "y=sales['Item_Outlet_Sales']\n",
    "x=sales.loc[:,sales.columns !='Item_Outlet_Sales']\n",
    "#print(x)\n",
    "randomforest.fit(x,y)\n",
    "score=cross_val_score(randomforest,x,y,cv=70)\n",
    "moyenne=score.mean()\n",
    "y_predit=randomforest.predict(x) \n",
    "print(moyenne)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
